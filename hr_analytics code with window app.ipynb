{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fdd8689",
   "metadata": {},
   "source": [
    "# Understanding  the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8ddf75",
   "metadata": {},
   "source": [
    "So bascially we have data set of the company who has 5000 employee.\n",
    "\n",
    "Both Male and Female are working.\n",
    "\n",
    "Data set have some information of the employee like they have own business and people are dependent on them or not\n",
    "\n",
    "Then data set have information like employees have authority to call or not.\n",
    "\n",
    "Then Employees have been rated or not by their supervisors.\n",
    "\n",
    "Data set has information about the Employee basic salary,bonus total salary.\n",
    "\n",
    "Company unit price,openingbalance,closingbalance,total_sales and volume alloted to the employee revealing in data set.\n",
    "\n",
    "From how many months employee working is also there.\n",
    "\n",
    "Employess age and Education Information is there in the data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca88f43a",
   "metadata": {},
   "source": [
    "# Data analysis and interpretations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f8681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required library\n",
    "import pandas as pd #importing panda library  for  data analysis\n",
    "import numpy as np  #importing numpy library  for mathematical operations\n",
    "import matplotlib.pyplot as plt  # matplotlib work like MATLAB\n",
    "import seaborn as sns    # importing seaborn library for data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609945fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data set\n",
    "df=pd.read_csv(r\"E:\\pkl\\hrdataset.csv\" )  # reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66342ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df #data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9bcc58",
   "metadata": {},
   "source": [
    "# Data set Description\n",
    "\n",
    "Gender - talks of the gender - Male or female\n",
    "\n",
    "Business - if the person has a business or no\n",
    "\n",
    "Age - age of the person\n",
    "\n",
    "Salary - CTC of the employee\n",
    "\n",
    "Dependants - number of people dependant on the person\n",
    "\n",
    "Months - duration of the person employed with the company\n",
    "\n",
    "Calls - if the person has authority to make calls or not\n",
    "\n",
    "Type - salary settlement type\n",
    "\n",
    "Billing - Subscribed to billing plans or no\n",
    "\n",
    "Unit sales - unit sale made by the person\n",
    "\n",
    "Total sales - total sales made by the person\n",
    "\n",
    "Rating - If he has been given a rating by a superior or no\n",
    "\n",
    "Bonus - amount received by a person as bonus for sales\n",
    "\n",
    "Base pay - Base pay of the employee\n",
    "\n",
    "Unit price - The Unit price of a sale\n",
    "\n",
    "Volume - volume allotted to a person\n",
    "\n",
    "Opening balance - The opening balance of an employee\n",
    "\n",
    "Low - lowest balance allotted to a person.\n",
    "\n",
    "Closing Balance- The closing balance of an employee\n",
    "\n",
    "Education- Educational background of an employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee554a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing deep copy to keep a copy of raw data for future references if needed.\n",
    "df1=df.copy()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10) #top 10 data of data set to analyze it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70254d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)  # bottom 10 of data of data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe01ea6",
   "metadata": {},
   "source": [
    "In this we can clearly see that openingbalance has nan value which should be replaced with approporiate  value to get better result.Also total sales has some empty data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d1d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5a8d3c",
   "metadata": {},
   "source": [
    "Data have 5000 rows and 20 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe76b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the size of dataset\n",
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad826078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() #describe functions tells all basic important function of data set like mean,max,count,25%,50%,75% of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7a2a59",
   "metadata": {},
   "source": [
    "Here we can notice that count of openingbalance,total sales and base pay is less than 5000.So we have definately some missing values\n",
    ".We should handle those value first so that we can better and correct interpretation and visualization of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aaefda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling empty cells of Total_Sales with nan\n",
    "df=df.replace(r'^\\s*$', float(np.NaN), regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail() #to check weather that values are replaced with nan or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375376e7",
   "metadata": {},
   "source": [
    "Here we can see that empty cells of Total_Sales are replaced with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd48455",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() #info tells type of data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff7e99c",
   "metadata": {},
   "source": [
    "Here we can analyze that Total_Sales is object type but it should be in float as it is total sales made by the person and value is in decimals.So we have to change the data type of Total_sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9879176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Total_Sales'] = df['Total_Sales'].astype('float64') #changing data type of data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53bbf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()  # rechecking the information to confirm weather the data type of Total_sales has changed or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31475ba1",
   "metadata": {},
   "source": [
    "Here we can confirm that Total_sales object is now float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e91a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum() #counts the total number of nan value present in data set.\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9ca4ac",
   "metadata": {},
   "source": [
    "Here we can observe that we have 23 nan value in Base_pay, 1476 nan value present in openingbalance and 16 nan value present in Total_sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c01af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating percentage of missing values\n",
    "total = df.isnull().sum().sort_values(ascending=False)  # Total count of missing values per column\n",
    "percent_1 = (df.isnull().sum() / df.shape[0]) * 100   # Percentage of missing values per column\n",
    "percent_2 = round(percent_1, 1).sort_values(ascending=False)  # Percentage rounded to 1 decimal point \n",
    "\n",
    "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])  # Concatenate the two \n",
    "                                                                          #Series into a DataFrame\n",
    "missing_data.head(3)  # Display the top 3 columns with missing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dc3312",
   "metadata": {},
   "source": [
    "\n",
    "Imputation\n",
    "\n",
    "\n",
    "\n",
    "Imputation is technique used for replacing the missing data with some reasonable value[Mean,Meadia and Mode] to retain most of the data or \n",
    "information of the dataset.In this case I would like to go with KNNimputer and mean to impute values base_pay and Total_Sales has less number of \n",
    "missing values.\n",
    "\n",
    "\n",
    "The idea in kNN methods is to identify 'k' samples in the dataset that are similar or close in the space. Then we use these 'k' samples to estimate the value of the missing data points. Each sample's missing values are imputed using the mean value of the 'k'-neighbors found in the dataset.\n",
    "\n",
    "\n",
    "I am imputing because it can give important information to predict the value of our dependent vairable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f484f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "x=df[['Base_pay','openingbalance','Total_Sales']]\n",
    "\n",
    "#create an object \n",
    "imputer= KNNImputer(n_neighbors=2)\n",
    "#fit and transform the values\n",
    "x=imputer.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dde34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the array into dataframe\n",
    "df[['Base_pay','openingbalance','Total_Sales']]=pd.DataFrame(x, columns =['Base_pay','openingbalance','Total_Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22afb601",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.isna().sum()     #now checking again the sum of toal nan value present in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1afce3",
   "metadata": {},
   "source": [
    "Here we can clearly see that sum of nan value present is 0.Hence we have successfully replaced all nan value present in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5648cf",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b68967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the total employee education wise\n",
    "degree_wise=df.Education.value_counts() #counting degree wise employee\n",
    "degree_wise #degree wise employee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c61ae2f",
   "metadata": {},
   "source": [
    "We can see that 2979 employee have pg degree ,1980 have done Graduation ,27 people has done Intermediate and 14 people with HIgh school or less.\n",
    "Here we can interpret that company prefer people  for job who are more educated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc19c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender_wise=df.Gender.value_counts() #counting total number of the employee gender wise.\n",
    "Gender_wise                          # gender wise employee."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbae7263",
   "metadata": {},
   "source": [
    "So number of male and females employess are almost equal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32754e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting how many employees have been rated by supervisor\n",
    "Rating_wise=df.Rating.value_counts() #counting the total number of ratings employee wise\n",
    "Rating_wise  #rating wise  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f96ab0",
   "metadata": {},
   "source": [
    "So we can see here that large number of employees have not been rated by supervisors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56735302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting how many employees authority to call\n",
    "call_wise=df.Calls.value_counts() #counting the total number of employee who has authority to call.\n",
    "call_wise   #number of employee has authority to call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab86ea4",
   "metadata": {},
   "source": [
    "So large number of employee have authority to call. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f7000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting number of people dependant on the person\n",
    "Dependancies_wise=df.Dependancies.value_counts() #counting total number of people dependednt on the person.\n",
    "Dependancies_wise # number of people dependent on the employee."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687751ed",
   "metadata": {},
   "source": [
    "Large Number of people are not dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796f1249",
   "metadata": {},
   "outputs": [],
   "source": [
    "Age_wise=df.Age.value_counts() #counting number of employess working in the company age wise.\n",
    "Age_wise #age wise employee."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac28271f",
   "metadata": {},
   "source": [
    "Here We can see that large number of employess working  who is in age of 50's. \n",
    "Also people above 80 are also working but there number is in just few number.\n",
    "So we can observe from this that company prefers experienced employees thats why large number of people above 50's are working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e779054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking count of salary settlement type\n",
    "Type_wise=df.Type.value_counts()   #counting employee salary settlement type.\n",
    "Type_wise  #no. of employee settlement type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85a84ef",
   "metadata": {},
   "source": [
    "We can observe that 2777 people have monthly salary settlement while 1195 people have two year salary settlement\n",
    "and 1028 people have year wise salary settlement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d8f69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking number of employee Subscribed to billing plans or no\n",
    "Billing_wise=df.Billing.value_counts()  # counting employee who has subscribed billing plans or not.  \n",
    "Billing_wise #number of employee subscribed to billing plans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26fbf92",
   "metadata": {},
   "source": [
    "So 2956 people have subscibed to billing plans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a99581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a grey background \n",
    "sns.set(style=\"darkgrid\")\n",
    "# Creating subplots with 10*10 figure size\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "# Ploting subplots with numerical variables\n",
    "sns.histplot(data=df, x=\"Salary\", kde=True, color=\"red\", ax=axs[0, 0])\n",
    "sns.histplot(data=df, x=\"Base_pay\", kde=True, color=\"olive\", ax=axs[0, 1])\n",
    "sns.histplot(data=df, x=\"Bonus\", kde=True, color=\"gold\", ax=axs[1, 0])\n",
    "sns.histplot(data=df, x=\"Age\", kde=True, color=\"black\", ax=axs[1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509bbdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.histplot(data=df, x=\"low\", kde=True, color=\"red\", ax=axs[0])# histogram for low column \n",
    "sns.histplot(data=df, x=\"Total_Sales\", kde=True, color=\"Navy\", ax=axs[1])# histogram for Total_sales column\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa8d0d5",
   "metadata": {},
   "source": [
    "# Box plot to see distribution\n",
    "\n",
    "From Box plot we can see the distribution of the data weather it is normally distributed or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46467b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a grey background \n",
    "sns.set(style=\"darkgrid\")\n",
    "# Creating subplots with 10*10 figure size\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "# Ploting subplots with variables\n",
    "sns.boxplot(data=df, x=\"Salary\", color=\"Lime\", ax=axs[0, 0])# boxplot to see Distribution of salary\n",
    "sns.boxplot(data=df, x=\"Base_pay\", color=\"olive\", ax=axs[0, 1])# boxplot to see Distribution of base_pay\n",
    "sns.boxplot(data=df, x=\"Bonus\", color=\"gold\", ax=axs[1, 0])# boxplot to see Distribution of bonus\n",
    "sns.boxplot(data=df, x=\"Age\", color=\"pink\", ax=axs[1, 1])# boxplot to see Distribution of age\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6868b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a grey background  \n",
    "sns.set(style=\"darkgrid\")\n",
    "# Creating subplots with 10*10 figure size\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "# Ploting subplots with all variables\n",
    "sns.boxplot(data=df, x=\"Unit_Price\", color=\"darkred\", ax=axs[0, 0])# boxplot to see outliers of unitprice \n",
    "sns.boxplot(data=df, x=\"Unit_Sales\", color=\"olive\", ax=axs[0, 1])# boxplot to see outliers of unit_sales\n",
    "sns.boxplot(data=df, x=\"openingbalance\", color=\"gold\", ax=axs[1, 0])# boxplot to see outliers of openingbalance\n",
    "sns.boxplot(data=df, x=\"closingbalance\", color=\"teal\", ax=axs[1, 1])# boxplot to see outliers of closingbalance\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1feede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settong a grey background  \n",
    "sns.set(style=\"darkgrid\")\n",
    "# Creating subplots with 10*10 figure size\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "# Ploting subplots with variables\n",
    "sns.boxplot(data=df, x=\"low\", color=\"red\", ax=axs[0,0])# boxplot to see outliers of low column \n",
    "sns.boxplot(data=df, x=\"Total_Sales\", color=\"Navy\", ax=axs[0,1])# boxplot to see outliers of Total_sales column\n",
    "sns.boxplot(data=df, x=\"Volume\", color=\"Yellow\", ax=axs[1,0])# boxplot to see outliers of volume column\n",
    "sns.boxplot(data=df, x=\"Months\", color=\"skyblue\", ax=axs[1,1])# boxplot to see outliers of months column\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5284da",
   "metadata": {},
   "source": [
    "remaining  columns like 'total_sales','low','openingbalance','closingbalance','unit_price','Volume','Months'\n",
    "this variables are not symetric becuase we an observe  that When the median is not in the middle of the box, and\n",
    "the whiskers are not about the same on both sides of the box,  thats why the distribution is non-symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d70f0e",
   "metadata": {},
   "source": [
    "# Statistical Approach QQplot to see the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6836b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pingouin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d8939c",
   "metadata": {},
   "source": [
    "### If the data is normally distributed, the points in the QQ-normal plot lie on a straight diagonal line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb6d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ plot for Salary\n",
    "import pingouin as pg \n",
    "pg.qqplot(df['Salary'],dist ='norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b1f614",
   "metadata": {},
   "source": [
    "We can see that data are distributed along qq lines hence we can conclude that Salary is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ab3245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ plot for Base_Pay\n",
    "pg.qqplot(df['Base_pay'],dist ='norm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e31d7a3",
   "metadata": {},
   "source": [
    "Here also points are along with the qq line,hence it is normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c3ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ plot for Bonus\n",
    "pg.qqplot(df['Bonus'],dist ='norm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb48175",
   "metadata": {},
   "source": [
    "Bonus is normally distributed here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459a365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ plot for Age\n",
    "pg.qqplot(df['Age'],dist ='norm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0acc8c",
   "metadata": {},
   "source": [
    "Age is also normally distributed as points are along with the qq line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5cb0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ plot for Unit_Price\n",
    "pg.qqplot(df['Unit_Price'],dist ='norm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66e418d",
   "metadata": {},
   "source": [
    "Unit_Price is not normally distributed as points are well far from qq-line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ca52df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ plot for Unit_Sales\n",
    "pg.qqplot(df['Unit_Sales'],dist ='norm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046e57b8",
   "metadata": {},
   "source": [
    "Unit sales are also not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31d2a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ plot for Openingbalance\n",
    "pg.qqplot(df['openingbalance'],dist ='norm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5170afba",
   "metadata": {},
   "source": [
    "Openingbalance is also not normally distributed aspoints are not along with the qq line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a4fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ plot for Closing Balance\n",
    "pg.qqplot(df['closingbalance'],dist ='norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17da924a",
   "metadata": {},
   "source": [
    "Closingbalance is also not normally distributed as it is not along with the qq line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1281c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QQ plot for Low\n",
    "pg.qqplot(df['low'],dist ='norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30103cfd",
   "metadata": {},
   "source": [
    "low is also not normally distributed ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcada366",
   "metadata": {},
   "source": [
    "# Finding out the correlation between variables using spearman rank correlation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ed402d",
   "metadata": {},
   "source": [
    "Pearson correlation assumes that the data we are comparing is normally distributed. When that assumption is not true, the correlation value is reflecting the true association. Spearman correlation does not assume that data is from a specific distribution, so it is a non-parametric correlation measure.\n",
    "\n",
    "Thats why we are going to use spearman rank correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8807da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.drop(['Business'],axis = 1)# Here I remove the business column becuase this \n",
    "                                    #variable comes under categorical feature\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_numeric = df3.select_dtypes(include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78440978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman rank correlation heatmap\n",
    "\n",
    "df3_numeric.corr(method=\"spearman\")# selecting the method as a sperman\n",
    "plt.figure(figsize=(20,8))# setting the figuresize\n",
    "\n",
    "heatmap = sns.heatmap(df3_numeric.corr(method = 'spearman').round(3), vmin=-1, \n",
    "vmax=1, annot=True)# annot = True means writting the data value in each cell.\n",
    "\n",
    "font2= {'family':'serif','color':'green','size':20}\n",
    "plt.title(\"Spearman Rank Correlation\",font2)\n",
    "plt.show()# displaying heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50efd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_numeric.corr(method='spearman',min_periods=1) #finding spearman co-relation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e9f63e",
   "metadata": {},
   "source": [
    "A Spearman correlation of 1 results when the two variables being compared are monotonically related, even if \n",
    "their relationship is not linear.\n",
    "Spearman rank correlation coefficient measures the monotonic relation between two variables. Its values range from -1 to +1 and can be interpreted as:\n",
    "\n",
    "   +1:   Perfectly monotonically increasing relationship.\n",
    "   \n",
    "   +0.8: Strong monotonically increasing relationship.\n",
    "   \n",
    "   +0.2: Weak monotonically increasing relationship.\n",
    "   \n",
    "     0:  Non-monotonic relation.\n",
    "     \n",
    "  -0.2:  Weak monotonically decreasing relationship.\n",
    "  \n",
    "  -0.8:  Strong monotonically decreasing relationship.\n",
    "  \n",
    "    -1:  Perfectly monotonically decreasing relationship.\n",
    "    \n",
    "\n",
    "---  Here we can see in above table  that spearman correlation between age and salary is 0.2 which means it\n",
    "     is weak monotonically increasing relationship.This means if age increases salary will too increase but not that much.\n",
    "    \n",
    "---  Spearmen correlation between salary and Total_sales is 0.99.\n",
    "     It means it is Perfectly monotonically increasing relationship and salary linearly increases with Total_sales\n",
    "     We can depict that employee who will do high Total_sales will get higher salary.\n",
    "        \n",
    "---   Similarly we can find relationshio with all variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1faa39",
   "metadata": {},
   "source": [
    "# The Relationship between Categorical variables and the Dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c727ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Looking the categorical columns\n",
    "df.select_dtypes(include=['object']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29d03c",
   "metadata": {},
   "source": [
    "we have above categorical columns now we are going to see this variables relationship with dependent variable which is salary of employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97d47a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,8)) #size of the figure\n",
    "sns.boxplot(data=df,x=\"Gender\", y=\"Salary\", color=\"Red\") #plotting the box plot for Salary vs gender.\n",
    "plt.title(\"Salary vs Gender\") #plot title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a29649",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))#isze of the plot\n",
    "sns.boxplot(data=df,x=\"Education\", y=\"Salary\", color=\"Green\") #box plot education wise with salary\n",
    "plt.title(\"Salary Vs Education\") #title of the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d39d407",
   "metadata": {},
   "source": [
    "From box plot we can onserve that mean salary of the employe who has done the PG is much more higher.\n",
    "This means that company pay more to employee with higer education.\n",
    "Similarly the mean of the employee who has done Graduation is high but less than PG people.\n",
    "Mean Salary of the high school and Intermediate is very low,this means that employee with high school or less and intermediate\n",
    "has occupied lower post in the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e9b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7)) #figure size\n",
    "sns.boxplot(x='Type',y='Salary',data=df,palette='winter') #Salary vs Salary settlement type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed78be2e",
   "metadata": {},
   "source": [
    "We can see that mean of the all three type of salary settlement is almost equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b437579",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7)) #title of the plot\n",
    "sns.boxplot(x='Business',y='Salary',data=df,palette='winter') #box plot Salary vs Employee.\n",
    "plt.title(\"Salary vs Business\") #title of the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02717bfd",
   "metadata": {},
   "source": [
    "mean of the both person who has business or not is almost same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cb3041",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7))# size of the plot\n",
    "sns.boxplot(data=df,x=\"Rating\", y=\"Salary\") #box plot rating vs salary\n",
    "plt.title(\"Salary vs Rating\")  #title of the salary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895dec12",
   "metadata": {},
   "source": [
    "It can be observed that mean of the Salary of the employees who have been rated by supervisor almost same.\n",
    "Hence rating is not affecting Salary of the employee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24445593",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7)) #size of the plot\n",
    "sns.boxplot(data=df,x=\"Dependancies\", y=\"Salary\") #box plot of dependancies vs Salary\n",
    "plt.title(\"Salary vs Dependancies\") #title of the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af867fc",
   "metadata": {},
   "source": [
    "Mean of the both employees who has dependancies or not is almost same.Hence we can conclude that salary is indepedent of the\n",
    "Dependancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ae935",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7)) #size of the plot\n",
    "sns.boxplot(data=df,x=\"Billing\", y=\"Salary\") #box plot of the Billing and Salary\n",
    "plt.title(\"Salary vs Billing\")  # title of the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38f82ae",
   "metadata": {},
   "source": [
    "# scatter plot to see relationship between numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f98791",
   "metadata": {},
   "source": [
    "lets draw scalar plot to see that how features that  we have are affecting our target variable Salary\n",
    "It will help us in data cleaning(dropping un-necessary data from our model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8810f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter plot vs salary and Base_pay\n",
    "#distribution of salary on the basis of Base_Pay\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.xlabel('Base_pay',fontsize=15)\n",
    "plt.ylabel('salary',fontsize=15)\n",
    "plt.title('Base_pay vs salary',fontsize=15)\n",
    "\n",
    "sns.scatterplot(x=df['Base_pay'],y=df['Salary'],color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965b596c",
   "metadata": {},
   "source": [
    "By observing the above plot here we see that we have linear relationship between Base_pay and Salary so we may keep base_pay in our feauture selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a910dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of salary on age to know the trend of salary increase according to age or not . \n",
    "plt.figure(figsize=(15,10))\n",
    "plt.xlabel('Age',fontsize=15)\n",
    "plt.ylabel('salary',fontsize=15)\n",
    "plt.title('age vs salary',fontsize=15)\n",
    "\n",
    "sns.scatterplot(x=df['Age'],y=df['Salary'],color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b9043",
   "metadata": {},
   "source": [
    "By observing the above plot here we dont see any special patterns in our data there is no relationship between Age & Salary \n",
    "and By using Spearman correlation we got 0.2 correlation between salary and \n",
    "Age thats why we can remove this column in feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08065816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter plot openingbalance vs salary\n",
    "#distribution of salary on the basis of openingbalance\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.xlabel('openingbalance',fontsize=20)\n",
    "plt.ylabel('salary',fontsize=20)\n",
    "plt.title('openingbalance vs salary',fontsize=20)\n",
    "\n",
    "sns.scatterplot(x=df['openingbalance'],y=df['Salary'],color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c74e43",
   "metadata": {},
   "source": [
    "we can see that there is no clear relationship between openingbalance and salary so we can remove it in feauture selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e82040",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of salary on Volume to know the trend of salary increase according to volume or not . \n",
    "plt.figure(figsize=(20,10))\n",
    "plt.xlabel('Volume',fontsize=20)\n",
    "plt.ylabel('salary',fontsize=20)\n",
    "plt.title('Volume vs salary',fontsize=20)\n",
    "\n",
    "sns.scatterplot(x=df['Volume'],y=df['Salary'],color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dafd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution salary on basis of bonus \n",
    "plt.figure(figsize=(20,10))\n",
    "plt.xlabel('Bonus',fontsize=20)\n",
    "plt.ylabel('salary',fontsize=20)\n",
    "plt.title('Bonus vs salary',fontsize=20)\n",
    "\n",
    "sns.scatterplot(x=df['Bonus'],y=df['Salary'],color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b2f486",
   "metadata": {},
   "source": [
    "By observing the above plot here we see that we have linear relationship between Bonus and Salary\n",
    "and By using Spearman correlation we got 100% correlation between salary and bonus thats why this may be  important variable \n",
    "for us.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da30571",
   "metadata": {},
   "source": [
    "# Data Cleaning and Justification "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90f3e67",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Nan values present were already replaced with mean value so that we can get more accurate graphs.\n",
    "In this Data set we will check now for outliers present in the data.\n",
    "Outliers are the extreme value who lies far from from maximuma and minimum of data.\n",
    "So sometime removing outliers increases efficicancy of the calculation and make the data normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7e0de9",
   "metadata": {},
   "source": [
    "# Checking Outliers\n",
    "\n",
    "\n",
    "Business\tAge\tSalary\tBase_pay\tBonus\tUnit_Price\tVolume\topeningbalance\tclosingbalance\t\n",
    "low\tUnit_Sales\tMonths Total_Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110b9bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7)) #size of the figure\n",
    "figure=df.boxplot(column=\"Age\") #box plot of the Age.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6eae85",
   "metadata": {},
   "source": [
    "We can see the outliers present in Age data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbdfa4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7)) #size of the plot\n",
    "figure=df.boxplot(column=\"Salary\") #box plot of the Salary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de469a7",
   "metadata": {},
   "source": [
    "We can observe that outliers are present in the salary.Mean Salary of the employee in this company is almost approximately 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7)) #size of the figure\n",
    "figure=df.boxplot(column=\"Base_pay\") #box plot of the Base_pay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fb9433",
   "metadata": {},
   "source": [
    "Base_pay has outliers and Mean Base_Pay of employees of this company is 40000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eccc58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7)) #size of the plot\n",
    "figure=df.boxplot(column=\"Bonus\") #box plot of the Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2c4027",
   "metadata": {},
   "source": [
    "Bonus has outliers and Mean Bonus is approximately 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90324df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7)) #size of the graph\n",
    "figure=df.boxplot(column=\"Unit_Price\") # box plot of the unit price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6949563d",
   "metadata": {},
   "source": [
    "### check outliers for age,salary,base pay,bonus,unit_Price,Volume,openingbalance,closingbalance,unit_Sales,Total_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527517b5",
   "metadata": {},
   "source": [
    "unit price is full of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3082024",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7)) #size of the plot.\n",
    "figure=df.boxplot(column=\"Volume\") #box plot of the volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8d2f96",
   "metadata": {},
   "source": [
    "Volume has large number of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bfc7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7)) #size of the plot\n",
    "figure=df.boxplot(column=\"openingbalance\") #box plot of the openingbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b56d105",
   "metadata": {},
   "source": [
    "openingbalance is full of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c658c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7)) #plotting the figure \n",
    "figure=df.boxplot(column=\"closingbalance\") #box plot of the closingbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242f9f0e",
   "metadata": {},
   "source": [
    "closebalance has also large number of the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29386dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7))  #figure size\n",
    "figure=df.boxplot(column=\"low\")  #plotting box plot of lowest balance alloted to the person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb98befe",
   "metadata": {},
   "source": [
    "it contains large number of outleirs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a445d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7)) #size of the plot\n",
    "figure=df.boxplot(column=\"Unit_Sales\") #box plot of the unit sales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b72467b",
   "metadata": {},
   "source": [
    "unit sales donot have outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef5d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7)) #size of the plot.\n",
    "figure=df.boxplot(column=\"Total_Sales\") #box plot of the Total_sales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3236e253",
   "metadata": {},
   "source": [
    "Total_sales donot contain any outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9045e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 7))  #size of the plot\n",
    "figure=df.boxplot(column=\"Months\") #box plot of the months"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f31113",
   "metadata": {},
   "source": [
    "It doesnot contain outliers.Mean duration of the employee working in the company is abput 28 months approximately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1c74b0",
   "metadata": {},
   "source": [
    "# pre-processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a99e4db",
   "metadata": {},
   "source": [
    "# Feature engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f035c325",
   "metadata": {},
   "source": [
    "# Finding out the correlation between variables using spearman rank correlation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c151aa",
   "metadata": {},
   "source": [
    "Pearson correlation assumes that the data we are comparing is normally distributed. When that assumption is not true, the correlation value is reflecting the true association. Spearman correlation does not assume that data is from a specific distribution, so it is a non-parametric correlation measure.\n",
    "\n",
    "Thats why we are going to use spearman rank correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e960e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.drop(['Business'],axis = 1)# Here I remove the business column becuase this variable comes under categorical feature\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29edef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_numeric = df3.select_dtypes(include='number')\n",
    "# Spearman rank correlation heatmap\n",
    "\n",
    "df3_numeric.corr(method=\"spearman\")# selecting the method as a sperman\n",
    "plt.figure(figsize=(20,8))# setting the figuresize\n",
    "\n",
    "heatmap = sns.heatmap(df3_numeric.corr(method = 'spearman').round(3), vmin=-1, \n",
    "vmax=1, annot=True) #annot = True means writting the data value in each cell.\n",
    "\n",
    "font2= {'family':'serif','color':'green','size':20}\n",
    "plt.title(\"Spearman Rank Correlation\",font2)\n",
    "plt.show()# displaying heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c950f87",
   "metadata": {},
   "source": [
    "Now Working on Numerically Highly corelated variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23f4fa1",
   "metadata": {},
   "source": [
    "From Heatmap I conclude that Some of our numerical variables have very high correlation between them which is above 80% coliniarity between dependent and other variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1abea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking to the percentage of correlation \n",
    "df3_numeric = df3.select_dtypes(include='number')\n",
    "df3_numeric.corr(method='spearman')*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec61b18",
   "metadata": {},
   "source": [
    "### Here we see that Base_pay, Bonus, Unit_Price, low, Unit_sales, Total_Sales This variables are highly correlated with each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294a7726",
   "metadata": {},
   "source": [
    "So we have two options either we can choose one variable and delete the remaing variables or going to take average of that columns\n",
    "\n",
    "So here I observed that between this colinear variables 'bonus' have high correlation with dependent variable thats why I choose to kept it and decided to delete the other variables which are highly corelated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43efc456",
   "metadata": {},
   "source": [
    "As per our visualization approach we conclude that Gender,Business,Dependancies,Calls,Type,Billing,Rating This variables dont affect on our dependent variable so as per this approach we can drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e4a489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the non-required variables\n",
    "dff = df.drop(columns=['Gender','Business','Dependancies','Calls','Type','Billing',\n",
    "                       'Rating','Base_pay','Unit_Price','low','Unit_Sales',\n",
    "                       'Total_Sales','openingbalance','closingbalance','Volume','Bonus'])\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdce3b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding to convert cateograical data to into numerical data\n",
    "\n",
    "dff['Education']=dff['Education'].map({'High School or less': 0, 'Intermediate': 1, \n",
    "                                       'Graduation': 2, 'PG': 3})\n",
    "#assigning high school =0,Intermediate =1 and gradaution=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f39e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.head() #head of the data set after label encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375653c5",
   "metadata": {},
   "source": [
    "We can clearly see that all cateogracial data has been changed into numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf6fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.info()# cross checking "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a37aa93",
   "metadata": {},
   "source": [
    "# Handaling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e17b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1=dff.quantile(0.25).round(3) # taking lower quantile into Q2\n",
    "Q3 =dff.quantile(0.75).round(3) # taking upper quarantile to Q3\n",
    "IQR = Q3 - Q1 #calculating inter quantile range\n",
    "print(IQR) #printing quatile range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdc9c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout = dff[~((dff < (Q1 - 1.5 * IQR)) |(dff > (Q3 + 1.5 * IQR))).any(axis=1)] #removing outliers from whole data set.\n",
    "dfout.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8692d9",
   "metadata": {},
   "source": [
    "# Sanity check weather outliers are removed or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49544617",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=dfout['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba32d1",
   "metadata": {},
   "source": [
    "there is no outliers in age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4da341",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=dfout['Salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5d997",
   "metadata": {},
   "source": [
    "there is no outliers in salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9590f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=dfout['Months'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2d257",
   "metadata": {},
   "source": [
    "there is no outliers in month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b8c9fd",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef8a79b",
   "metadata": {},
   "source": [
    "In Model Building we have to prepare the data set for machine learning algorithm.Also we have to prepare the data in a such a way that \n",
    "it gives better efficiancy.For stability of data set we can drop the highly co-related features in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f9fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =dff.drop(['Salary'],axis=1) #dropping highly co-related features.\n",
    "x #new datas set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a76db5",
   "metadata": {},
   "source": [
    "This is our dependednt variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e5a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependent variables to y\n",
    "y = dff['Salary']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0bceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size = 0.3, \n",
    "                                                    random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceaab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd6f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15012a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c942e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6f65fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data normalization with sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc= StandardScaler()\n",
    "# fit scaler on training data\n",
    "x_train = sc.fit_transform(x_train)\n",
    "\n",
    "# transform testing data\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a83c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212a950e",
   "metadata": {},
   "source": [
    "# Machine learning techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01127038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Create and train the Linear Regression model\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = model_lr.predict(x_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "mape_lr = np.mean(np.abs((y_test - y_pred_lr) / np.abs(y_test)))\n",
    "accuracy_lr = 100 * (1 - mape_lr)\n",
    "\n",
    "# Print the performance metrics for Linear Regression\n",
    "print('Linear Regression Metrics:')\n",
    "print('Mean Absolute Error (MAE):', mae_lr)\n",
    "print('Mean Squared Error (MSE):', mse_lr)\n",
    "print('Root Mean Squared Error (RMSE):', rmse_lr)\n",
    "print('Mean Absolute Percentage Error (MAPE):', round(mape_lr * 100, 2))\n",
    "print('Accuracy:', round(accuracy_lr, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7773cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Create and train the Decision Tree model\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = np.mean(np.abs((y_test - y_pred) / np.abs(y_test)))\n",
    "accuracy = 100 * (1 - mape)\n",
    "\n",
    "# Print the performance metrics\n",
    "print('Mean Absolute Error (MAE):', mae)\n",
    "print('Mean Squared Error (MSE):', mse)\n",
    "print('Root Mean Squared Error (RMSE):', rmse)\n",
    "print('Mean Absolute Percentage Error (MAPE):', round(mape * 100, 2))\n",
    "print('Accuracy:', round(accuracy, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f95dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04d2c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create and train the Random Forest model\n",
    "model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_rf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = model_rf.predict(x_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "mape_rf = np.mean(np.abs((y_test - y_pred_rf) / np.abs(y_test)))\n",
    "accuracy_rf = 100 * (1 - mape_rf)\n",
    "\n",
    "# Print the performance metrics for Random Forest\n",
    "print('Random Forest Metrics:')\n",
    "print('Mean Absolute Error (MAE):', mae_rf)\n",
    "print('Mean Squared Error (MSE):', mse_rf)\n",
    "print('Root Mean Squared Error (RMSE):', rmse_rf)\n",
    "print('Mean Absolute Percentage Error (MAPE):', round(mape_rf * 100, 2))\n",
    "print('Accuracy:', round(accuracy_rf, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f54d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Create and train the XGBoost model\n",
    "model_xgb = xgb.XGBRegressor()\n",
    "model_xgb.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = model_xgb.predict(x_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "rmse_xgb = np.sqrt(mse_xgb)\n",
    "mape_xgb = np.mean(np.abs((y_test - y_pred_xgb) / np.abs(y_test)))\n",
    "accuracy_xgb = 100 * (1 - mape_xgb)\n",
    "\n",
    "# Print the performance metrics for XGBoost\n",
    "print('XGBoost Metrics:')\n",
    "print('Mean Absolute Error (MAE):', mae_xgb)\n",
    "print('Mean Squared Error (MSE):', mse_xgb)\n",
    "print('Root Mean Squared Error (RMSE):', rmse_xgb)\n",
    "print('Mean Absolute Percentage Error (MAPE):', round(mape_xgb * 100, 2))\n",
    "print('Accuracy:', round(accuracy_xgb, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42971165",
   "metadata": {},
   "source": [
    "# Step 8 : Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce80d4d9",
   "metadata": {},
   "source": [
    "Cross-validation is a resampling method that uses different portions of the data to test and \n",
    "train a model on different iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac12bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation for our model\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "model=LinearRegression()\n",
    "ssplit=ShuffleSplit(n_splits=10,test_size=0.30)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "results=cross_val_score(model,x,y,cv=ssplit)\n",
    "print(results)\n",
    "print(\"\\nMean Cross-validation Accuracy:\",np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01980886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation for our model\n",
    "\n",
    "model=DecisionTreeRegressor(max_depth=3)\n",
    "ssplit=ShuffleSplit(n_splits=10,test_size=0.30)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "results=cross_val_score(model,x,y,cv=ssplit)\n",
    "print(results)\n",
    "print(\"\\nMean Cross-validation Accuracy:\",np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4801bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation for our model\n",
    "model=RandomForestRegressor(random_state=5)\n",
    "ssplit=ShuffleSplit(n_splits=10,test_size=0.30)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "results=cross_val_score(model,x,y,cv=ssplit)\n",
    "print(results)\n",
    "print(\"\\nMean Cross-validation Accuracy:\",np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a551af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Define ShuffleSplit cross-validation\n",
    "ssplit = ShuffleSplit(n_splits=10, test_size=0.3)\n",
    "\n",
    "# Perform cross-validation\n",
    "results_xgb = cross_val_score(model_xgb, x, y, cv=ssplit)\n",
    "\n",
    "# Print results for each fold\n",
    "print(\"Cross-validation results for each fold:\")\n",
    "print(results_xgb)\n",
    "\n",
    "# Print mean accuracy across all folds\n",
    "print(\"\\nMean Cross-validation Accuracy:\", np.mean(results_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a35600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Example: Train a model (XGBoost Regressor as an example)\n",
    "model_xgb = XGBRegressor()\n",
    "model_xgb.fit(x_train, y_train)\n",
    "\n",
    "# Save the trained model to a file using pickle\n",
    "with open('hr.pkl', 'wb') as file:\n",
    "    pickle.dump(model_xgb, file)\n",
    "\n",
    "print(\"Model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028bc598",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('schr.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(sc, scaler_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a5890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained XGBoost model\n",
    "with open('hr.pkl', 'rb') as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "\n",
    "# Load the scaler used during training\n",
    "with open('schr.pkl', 'rb') as scaler_file:\n",
    "    scaler = pickle.load(scaler_file)\n",
    "\n",
    "# Create Tkinter GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Salary Prediction\")\n",
    "\n",
    "# Function to get prediction from input fields\n",
    "def get_prediction():\n",
    "    # Get input values from entry fields\n",
    "    age = float(age_entry.get())\n",
    "    experience = float(experience_entry.get())\n",
    "    education = int(education_entry.get())\n",
    "\n",
    "    # Create a numpy array with input values\n",
    "    input_data = np.array([[age, experience, education]])\n",
    "\n",
    "    # Normalize the input data using the scaler\n",
    "    input_data_scaled = scaler.transform(input_data)\n",
    "\n",
    "    # Predict using the loaded model\n",
    "    prediction = model.predict(input_data_scaled)\n",
    "\n",
    "    # Display prediction result\n",
    "    result_label.config(text=f\"Predicted Salary: ${prediction[0]:,.2f}\")\n",
    "\n",
    "# Create labels and entry fields for input features\n",
    "tk.Label(root, text=\"Age\").grid(row=0, column=0)\n",
    "tk.Label(root, text=\"Experience (Months)\").grid(row=1, column=0)\n",
    "tk.Label(root, text=\"Education Level (0-3)\").grid(row=2, column=0)\n",
    "\n",
    "age_entry = tk.Entry(root)\n",
    "experience_entry = tk.Entry(root)\n",
    "education_entry = tk.Entry(root)\n",
    "\n",
    "age_entry.grid(row=0, column=1)\n",
    "experience_entry.grid(row=1, column=1)\n",
    "education_entry.grid(row=2, column=1)\n",
    "\n",
    "# Button to trigger prediction\n",
    "predict_button = tk.Button(root, text=\"Predict\", command=get_prediction)\n",
    "predict_button.grid(row=3, columnspan=2)\n",
    "\n",
    "# Label to display prediction result\n",
    "result_label = tk.Label(root, text=\"\")\n",
    "result_label.grid(row=4, columnspan=2)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16080c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb0f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the content of the updated Streamlit script\n",
    "streamlit_code = \"\"\"\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained XGBoost model and scaler\n",
    "with open('hr.pkl', 'rb') as model_file:\n",
    "    model = pickle.load(model_file)\n",
    "\n",
    "with open('schr.pkl', 'rb') as scaler_file:\n",
    "    scaler = pickle.load(scaler_file)\n",
    "\n",
    "# Create the web app\n",
    "st.title('Salary Prediction App')\n",
    "\n",
    "# Input fields\n",
    "age = st.number_input('Age', min_value=0, max_value=120, value=30)\n",
    "education = st.selectbox('Education Level', ['High School or less', 'Intermediate', 'Graduation', 'PG'])\n",
    "experience_months = st.number_input('Months of Experience', min_value=0, max_value=600, value=60)  # Assuming max experience is 50 years\n",
    "\n",
    "# Convert education to numeric encoding\n",
    "education_mapping = {'High School or less': 0, 'Intermediate': 1, 'Graduation': 2, 'PG': 3}\n",
    "education_encoded = education_mapping[education]\n",
    "\n",
    "# Prepare the feature vector\n",
    "features = np.array([[age, education_encoded, experience_months]], dtype=np.float64)\n",
    "\n",
    "# Scale the features\n",
    "features_scaled = scaler.transform(features)\n",
    "\n",
    "# Predict salary\n",
    "predicted_salary = model.predict(features_scaled)\n",
    "\n",
    "# Display the result\n",
    "st.write(f\"Predicted Salary: ${predicted_salary[0]:,.2f}\")\n",
    "\"\"\"\n",
    "\n",
    "# Specify the file path where the hrapp.py file will be saved\n",
    "file_path = 'hrapp.py'\n",
    "\n",
    "# Write the content to the file\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(streamlit_code)\n",
    "\n",
    "print(f\"File '{file_path}' has been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6948caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#streamlit run hrapp.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eeef01",
   "metadata": {},
   "source": [
    "# Results and Recommendations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699b6649",
   "metadata": {},
   "source": [
    "# Results:\n",
    "    \n",
    "Data analysis and interpretations\n",
    "\n",
    "1.Data set was read.\n",
    "\n",
    "2. Head and tail of the data set was visualized.\n",
    "\n",
    "\n",
    "3. Data basic information was seen like mean,max,etc.\n",
    "\n",
    "\n",
    "4. Shape of the data is 5000 row and 20 column.\n",
    "\n",
    "\n",
    "5. Sum of null values were seen and null values were present in the data set.\n",
    "\n",
    "\n",
    "6. null values were successfully replaced with the help of KNN imputer.\n",
    "\n",
    "\n",
    "7. Total_sales has some empty spaces which was replaced with nan then replaced by mean value.\n",
    "\n",
    "\n",
    "8. various category vs there count were plotted to understand the data.\n",
    "\n",
    "\n",
    "9. Gender- There is not much difference between male and femlae employee.\n",
    "\n",
    "\n",
    "10.Companies has hired large number of employee which can be seen in month column.\n",
    "\n",
    "\n",
    "11.Most of the employee are seniors with mean age of 51.\n",
    "\n",
    "\n",
    "12.Few data normalization checked,and they were not normal.It means they have outliers.\n",
    "\n",
    "\n",
    "13 Spearman co-relation was obtained.Spearmen correlation between salary and Total_sales is 0.99.\n",
    "\n",
    "\n",
    "13.a. It means it is Perfectly monotonically increasing relationship and salary linearly increases with Total_sales.\n",
    "\n",
    "\n",
    "13.b. We can depict that employee who will do high Total_sales will get higher salary.Similary all features can be related in spearman table.\n",
    "\n",
    "\n",
    "14 Cateograical and dependent variable analyzed.\n",
    "\n",
    "\n",
    "15. Both Male and female working in almost equal number in the company.\n",
    "\n",
    "\n",
    "16.We can depicts from this graph that both female and male drawing almost equal salary(total number wise) from company.\n",
    "\n",
    "\n",
    "17. Mean of the both person who has business or not is almost same.\n",
    "\n",
    "\n",
    "18.Large number of employee have authority to call.\n",
    "\n",
    "\n",
    "19. We can observe that employee with PG degree draws salary  approximately ranges from almost 50000 to 2 lac.\n",
    "Employee with Graduation is drawing salary from approximately 25000 to 1.25 lac.\n",
    "Salary of High School or less  and Intermediate is drawing salary less than 25000.\n",
    "\n",
    "20.We can observe that high number of unit sales ,higher will be the salary.\n",
    "\n",
    "\n",
    "21.We can see that higher number of sales,higher is the salary.\n",
    "\n",
    "\n",
    "22.we can observe that company has hired high number of new employees. In last four months company has hired.\n",
    "\n",
    "almost 765 employees. Also company has 269 employees who are giving there services from 72 months.\n",
    "\n",
    "\n",
    "23. by scatter plot we can see the relation between numerical data and salary.\n",
    "\n",
    "24 In Data cleaning all nan values were already replaced with mean.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Data Cleaning and justification\n",
    "\n",
    "25. Outliers were checked for all numberical data and it was found that Many features has large number of outlers.\n",
    "\n",
    "26. Outliers were removed using IQR method .\n",
    "\n",
    "27. varification done weather outliers were removed by re-plotting the box-plot and it was found that outliers were successfully removed.\n",
    "\n",
    "\n",
    " Feature Engineering\n",
    "\n",
    "28. Data set has cateograical data which have to change ino numberical data for machine learning.\n",
    "\n",
    "29. Feature selection is a technique where we choose those features in our data that contribute most to the target variable.\n",
    "\n",
    "30. Here we can see that in scores business, calls, type, billing, rating,gender,openingbalance,closing balance has less contribution to target variable.\n",
    "so we can drop them.\n",
    "31. Using label-encoding all cateograical data was changed to numerical data.\n",
    "\n",
    "32. spearman Co-relation method was used to check co-relation between two feautres.\n",
    "\n",
    "33. Highly co-related datas have to be removed to make the model stable.\n",
    "\n",
    "34. Thresold was kept 0.80 and it was found that Basic_pay,Bonus,Total_Sales and Unit_sales has the co-relation above 0.8.\n",
    "\n",
    "\n",
    " Model Building\n",
    "    \n",
    "35. Cateogrical data like calls,rating,dependancies,billing,type,Business were dropped.\n",
    "\n",
    "36. Highly co-related data were dropped.\n",
    "\n",
    "37. Model were split into x_train,y_train,x_test,y_test.\n",
    "\n",
    "38. Normalization using standardscalar done to scale down our target vairable.\n",
    "\n",
    "\n",
    " Machine learning techniques \n",
    "\n",
    "39.  ### Linear regression accuracy:-78.27\n",
    "    \n",
    "\n",
    "40. #### Decission Tree Regression :- 99.35\n",
    "\n",
    "41. Accuracy came good but we should try  another techniques to get better accuracy.\n",
    "\n",
    "42. ### Random Forest Regression algorithm were used in the model now.99.09\n",
    "\n",
    "43. #### accuracy comes around\n",
    "\n",
    "43 b. Xgboost:-99.24\n",
    "\n",
    "44. Desired accuracy were achieved. And we can say that our model is working correct.\n",
    "\n",
    "45. ### Linear regression were tried and accuracy we got less accuracy.\n",
    "\n",
    "\n",
    "Step 8 :- Cross Validation\n",
    "    \n",
    "47.Cross-validation is a resampling method that uses different portions of the data to test and  train a model on different iterations.\n",
    "\n",
    "\n",
    "\n",
    "Verdict :- After explotatotry analysis,data cleaning and model building,various machine learning techniques were tried.\n",
    "           In our model we got it is random forest regreesor giving highest accuracy as compared to rest of all the models.\n",
    "        \n",
    "### Recommendations :\n",
    "\n",
    "1. From the analysis done, it was observed that employee with high experience giving high sales to the company.\n",
    "   So company should hire experienced candidate more.\n",
    "\n",
    "2. Employee performance was dominated by age,months(services to the company), education.\n",
    "\n",
    "3. So strategic approach to the efficient management and maximum business gain to the  company can be\n",
    "done by  hiring  the employee  who is experienced and has high education like PG.\n",
    "\n",
    "4. Salary component mostly affected by the age,months and education.Also company total_sales are direcly related to salary.\n",
    "\n",
    "5. So hr department can plan their approach by keeping above facts in mind for hiring the candidate who can help them to get maximum sales,which can benift the company most.\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
